{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Data for Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Predict tracks for a playlist given its title only\n",
    "Predict tracks for a playlist given its title and the first track\n",
    "Predict tracks for a playlist given its title and the first 5 tracks\n",
    "Predict tracks for a playlist given its first 5 tracks (no title)\n",
    "Predict tracks for a playlist given its title and the first 10 tracks\n",
    "Predict tracks for a playlist given its first 10 tracks (no title)\n",
    "Predict tracks for a playlist given its title and the first 25 tracks\n",
    "Predict tracks for a playlist given its title and 25 random tracks\n",
    "Predict tracks for a playlist given its title and the first 100 tracks\n",
    "Predict tracks for a playlist given its title and 100 random tracks\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "variants=[1,5,10,25,100]\n",
    "random=[25,100]\n",
    "only title -> 1\n",
    "1 track -> 1\n",
    "5 tracks -> 2\n",
    "10 tracks -> 2\n",
    "25 -> 2\n",
    "100 -> 2\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Background data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed10000\n",
      "processed20000\n",
      "processed30000\n",
      "processed40000\n",
      "processed50000\n",
      "processed60000\n",
      "processed70000\n",
      "processed80000\n",
      "processed90000\n",
      "processed100000\n",
      "processed110000\n",
      "processed120000\n",
      "processed130000\n",
      "processed140000\n",
      "processed150000\n",
      "processed160000\n",
      "processed170000\n",
      "processed180000\n",
      "processed190000\n",
      "processed200000\n",
      "processed210000\n",
      "processed220000\n",
      "processed230000\n",
      "processed240000\n",
      "processed250000\n",
      "processed260000\n",
      "processed270000\n",
      "processed280000\n",
      "processed290000\n",
      "processed300000\n",
      "processed310000\n",
      "processed320000\n",
      "processed330000\n",
      "processed340000\n",
      "processed350000\n",
      "processed360000\n",
      "processed370000\n",
      "processed380000\n",
      "processed390000\n",
      "processed400000\n",
      "processed410000\n",
      "processed420000\n",
      "processed430000\n",
      "processed440000\n",
      "processed450000\n",
      "processed460000\n",
      "processed470000\n",
      "processed480000\n",
      "processed490000\n",
      "processed500000\n",
      "processed510000\n",
      "processed520000\n",
      "processed530000\n",
      "processed540000\n",
      "processed550000\n",
      "processed560000\n",
      "processed570000\n",
      "processed580000\n",
      "processed590000\n",
      "processed600000\n",
      "processed610000\n",
      "processed620000\n",
      "processed630000\n",
      "processed640000\n",
      "processed650000\n",
      "processed660000\n",
      "processed670000\n",
      "processed680000\n",
      "processed690000\n",
      "processed700000\n",
      "processed710000\n",
      "processed720000\n",
      "processed730000\n",
      "processed740000\n",
      "processed750000\n"
     ]
    }
   ],
   "source": [
    "#get trackslist to eliminate that are not covered from the refset while evaluating\n",
    "import itertools as it\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "path='../../data'\n",
    "\n",
    "\n",
    "filenames = os.listdir(path)[:750]\n",
    "\n",
    "count=0\n",
    "\n",
    "tracksSet=[]\n",
    "pidLen=[]\n",
    "pidDate=[]\n",
    "trainingDataPids=[]\n",
    "\n",
    "for filename in sorted(filenames):\n",
    "    if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "        fullpath = os.sep.join((path, filename))\n",
    "        f = open(fullpath)\n",
    "        js = f.read()\n",
    "        f.close()\n",
    "        mpd_slice = json.loads(js)\n",
    "        for playlist in mpd_slice['playlists']:\n",
    "            playlistId=str(playlist['pid'])\n",
    "            numTracks=playlist['num_tracks']\n",
    "            lastMod=playlist['modified_at']\n",
    "            trainingDataPids.append(playlistId)\n",
    "            pidLen.append(numTracks)\n",
    "            pidDate.append(lastMod)\n",
    "            for track in playlist['tracks']:\n",
    "                tracksSet.append(track['track_uri'])\n",
    "            count=count+1\n",
    "            if count % 10000 ==0:\n",
    "                print 'processed' + str(count)\n",
    "tracksSet=set(tracksSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1963619, 750000, 750000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tracksSet), len(pidLen), len(pidDate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Background data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fileObj = open('filenamesBackGroundData.pkl', 'w')\n",
    "pickle.dump(filenames, fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "import pickle\n",
    "fileObj = open('backgroundDataPids.pkl', 'w')\n",
    "pickle.dump(trainingDataPids, fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fileObj = open('backGroundtracksSet750.pkl', 'w')\n",
    "pickle.dump(tracksSet, fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed10000\n",
      "processed20000\n",
      "processed30000\n",
      "processed40000\n",
      "processed50000\n",
      "processed60000\n",
      "processed70000\n",
      "processed80000\n",
      "processed90000\n",
      "processed100000\n",
      "processed110000\n",
      "processed120000\n",
      "processed130000\n",
      "processed140000\n",
      "processed150000\n",
      "processed160000\n",
      "processed170000\n",
      "processed180000\n",
      "processed190000\n",
      "processed200000\n",
      "processed210000\n",
      "processed220000\n",
      "processed230000\n",
      "processed240000\n",
      "processed250000\n"
     ]
    }
   ],
   "source": [
    "trainingfilenames = os.listdir(path)[750:]\n",
    "\n",
    "count=0\n",
    "\n",
    "trainingCandidateMeta={}\n",
    "for filename in sorted(trainingfilenames):\n",
    "    if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "        fullpath = os.sep.join((path, filename))\n",
    "        f = open(fullpath)\n",
    "        js = f.read()\n",
    "        f.close()\n",
    "        mpd_slice = json.loads(js)\n",
    "        for playlist in mpd_slice['playlists']:\n",
    "            playlistId=playlist['pid']\n",
    "            numTracks=playlist['num_tracks']\n",
    "            lastMod=playlist['modified_at']\n",
    "            tracksList=[]\n",
    "            for track in playlist['tracks']:\n",
    "                tracksList.append(track['track_uri'])\n",
    "            overlapWithBackground=len(set(tracksList)&tracksSet)\n",
    "            overlapWithBackground1=len(set(tracksList[:1])&tracksSet)\n",
    "            overlapWithBackground5=len(set(tracksList[:5])&tracksSet)\n",
    "            overlapWithBackground10=len(set(tracksList[:10])&tracksSet)\n",
    "            pOverlap=overlapWithBackground*1.0/numTracks\n",
    "            trainingCandidateMeta[playlistId]=[numTracks,lastMod,overlapWithBackground,overlapWithBackground1,overlapWithBackground5,overlapWithBackground10,pOverlap]\n",
    "            count=count+1\n",
    "            if count % 10000 ==0:\n",
    "                print 'processed' + str(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855477, [226, 1509494400, 224, 1, 5, 10, 0.9911504424778761])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingCandidateMeta.items()[100] #(855477, [226, 1509494400, 224, 1, 5, 10, 0.9911504424778761])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fileObj = open('trainingTestingCandidateMeta750.pkl', 'w')\n",
    "pickle.dump(trainingCandidateMeta, fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selectHist=[]\n",
    "Hist=[]\n",
    "for k, v in trainingCandidateMeta.items():\n",
    "    if v[-1]==1.0:\n",
    "        selectHist.append(v[0])\n",
    "    Hist.append(v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138471, 250000)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selectHist),len(Hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "hist_1, _ = np.histogram(selectHist, bins=50)\n",
    "hist_2, _ = np.histogram(Hist, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8054321843562913"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "250000*1.0/138471"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93217840000000007"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minima = np.minimum(hist_1*1.8, hist_2)#normalise by the ratio\n",
    "intersection = np.true_divide(np.sum(minima), np.sum(hist_2))\n",
    "intersection#print histogram intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12969, 53905)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(filter(lambda x: x > 100, selectHist))) , len(list(filter(lambda x: x > 100, Hist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76078, 133473)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(filter(lambda x: x > 25 and x< 100, selectHist))) , len(list(filter(lambda x: x > 25 and x< 100, Hist)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12969, 89491, 128457, 137258, 138471)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training100CandidatePid=[]\n",
    "training100RandCandidatePid=[]\n",
    "training25CandidatePid=[]\n",
    "training25RandCandidatePid=[]\n",
    "training10CandidatePid=[]\n",
    "training5CandidatePid=[]\n",
    "training1CandidatePid=[]\n",
    "for k, v in trainingCandidateMeta.items():\n",
    "    if v[-1]==1.0:\n",
    "        if v[0]>100:\n",
    "            training100CandidatePid.append(k)\n",
    "        if v[0]>25:\n",
    "            training25CandidatePid.append(k)\n",
    "        if v[0]>10:\n",
    "            training10CandidatePid.append(k)\n",
    "        if v[0]>5:\n",
    "            training5CandidatePid.append(k)\n",
    "        training1CandidatePid.append(k)\n",
    "        \n",
    "    if v[0]>100 and v[-1]>=0.99:\n",
    "        training100RandCandidatePid.append(k)\n",
    "    if v[0]>25 and v[-1]>=0.99:\n",
    "        training25RandCandidatePid.append(k)\n",
    "\n",
    "len(training100CandidatePid),len(training25CandidatePid), len(training10CandidatePid), len(training5CandidatePid), len(training1CandidatePid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23800, 100546)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training100RandCandidatePid),len(training25RandCandidatePid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shuffle the candidate pids\n",
    "from random import shuffle\n",
    "shuffle(training100CandidatePid)\n",
    "shuffle(training25CandidatePid)\n",
    "shuffle(training10CandidatePid)\n",
    "shuffle(training5CandidatePid)\n",
    "shuffle(training1CandidatePid)\n",
    "shuffle(training100RandCandidatePid)\n",
    "shuffle(training25RandCandidatePid)\n",
    "training100Pid=training100CandidatePid[:5000]\n",
    "training25Pid= list(set(training25CandidatePid) - set(training100Pid))[:5000]\n",
    "training10Pid= list(set(training10CandidatePid) - set(training100Pid+training25Pid))[:10000]\n",
    "training5Pid= list(set(training5CandidatePid) - set(training100Pid+training25Pid+training10Pid))[:10000]\n",
    "training1Pid= list(set(training1CandidatePid) - set(training100Pid+training25Pid+training10Pid+training5Pid))[:5000]\n",
    "trainingOnlyTitlePid= list(set(training1CandidatePid) - set(training100Pid+training25Pid+training10Pid+training5Pid+training1Pid))[:5000]\n",
    "training100RandPid= list(set(training100RandCandidatePid) - set(training100Pid+training25Pid+training10Pid+training5Pid+training1Pid+trainingOnlyTitlePid))[:5000]\n",
    "training25RandPid= list(set(training25RandCandidatePid) - set(training100Pid+training25Pid+training10Pid+training5Pid+training1Pid+trainingOnlyTitlePid+training100RandPid))[:5000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000, 5000, 5000, 10000, 10000, 5000, 5000)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training100Pid),len(training100RandPid),len(training25Pid),len(training25RandPid),len(training10Pid),len(training5Pid),len(training1Pid),len(trainingOnlyTitlePid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[112, 1508457600, 112, 1, 5, 10, 1.0]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingCandidateMeta[training10Pid[100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AllTrain=training100Pid+training25Pid+training10Pid+training5Pid+training1Pid+trainingOnlyTitlePid+training100RandPid+training25RandPid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leftOvers=set(trainingCandidateMeta.keys())-set(AllTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "leftOverPlaylistIdsAfterBackgroundAndTrain1.pkl\n",
    "training100Pid.pkl\n",
    "training100RandPid.pkl\n",
    "training10Pid.pkl\n",
    "training1Pid.pkl\n",
    "training25Pid.pkl\n",
    "training25RandPid.pkl\n",
    "training5Pid.pkl\n",
    "trainingOnlyTitlePid.pkl\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "fileObj = open('training100Pid.pkl', 'w')\n",
    "pickle.dump(training100Pid, fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(leftOvers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "leftOverPids= pickle.load(open('./SplitsInformation/leftOverPlaylistIdsAfterBackgroundAndTrain1.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create splits for testing; 500 in each test track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3878, 55371, 84874, 91616, 92561)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing100CandidatePid=[]\n",
    "testing100RandCandidatePid=[]\n",
    "testing25CandidatePid=[]\n",
    "testing25RandCandidatePid=[]\n",
    "testing10CandidatePid=[]\n",
    "testing5CandidatePid=[]\n",
    "testing1CandidatePid=[]\n",
    "for k, v in trainingCandidateMeta.items():\n",
    "    if k in leftOverPids:\n",
    "        if v[-1]==1.0:\n",
    "            if v[0]>100:\n",
    "                testing100CandidatePid.append(k)\n",
    "            if v[0]>25:\n",
    "                testing25CandidatePid.append(k)\n",
    "            if v[0]>10:\n",
    "                testing10CandidatePid.append(k)\n",
    "            if v[0]>5:\n",
    "                testing5CandidatePid.append(k)\n",
    "            testing1CandidatePid.append(k)\n",
    "\n",
    "        if v[0]>100 and v[-1]>=0.99:\n",
    "            testing100RandCandidatePid.append(k)\n",
    "        if v[0]>25 and v[-1]>=0.99:\n",
    "            testing25RandCandidatePid.append(k)\n",
    "\n",
    "len(testing100CandidatePid),len(testing25CandidatePid), len(testing10CandidatePid), len(testing5CandidatePid), len(testing1CandidatePid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "shuffle(testing100CandidatePid)\n",
    "shuffle(testing25CandidatePid)\n",
    "shuffle(testing10CandidatePid)\n",
    "shuffle(testing5CandidatePid)\n",
    "shuffle(testing1CandidatePid)\n",
    "shuffle(testing100RandCandidatePid)\n",
    "shuffle(testing25RandCandidatePid)\n",
    "testing100Pid=testing100CandidatePid[:500]\n",
    "testing25Pid= list(set(testing25CandidatePid) - set(testing100Pid))[:500]\n",
    "testing10Pid= list(set(testing10CandidatePid) - set(testing100Pid+testing25Pid))[:1000]\n",
    "testing5Pid= list(set(testing5CandidatePid) - set(testing100Pid+testing25Pid+testing10Pid))[:1000]\n",
    "testing1Pid= list(set(testing1CandidatePid) - set(testing100Pid+testing25Pid+testing10Pid+testing5Pid))[:500]\n",
    "testingOnlyTitlePid= list(set(testing1CandidatePid) - set(testing100Pid+testing25Pid+testing10Pid+testing5Pid+testing1Pid))[:500]\n",
    "testing100RandPid= list(set(testing100RandCandidatePid) - set(testing100Pid+testing25Pid+testing10Pid+testing5Pid+testing1Pid+testingOnlyTitlePid))[:500]\n",
    "testing25RandPid= list(set(testing25RandCandidatePid) - set(testing100Pid+testing25Pid+testing10Pid+testing5Pid+testing1Pid+testingOnlyTitlePid+testing100RandPid))[:500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500, 500, 500, 1000, 1000, 500, 500)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing100Pid),len(testing100RandPid),len(testing25Pid),len(testing25RandPid),len(testing10Pid),len(testing5Pid),len(testing1Pid),len(testingOnlyTitlePid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[45, 1455926400, 45, 1, 5, 10, 1.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingCandidateMeta[testing10Pid[398]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AllTesting=testing100Pid+testing25Pid+testing10Pid+testing5Pid+testing1Pid+testingOnlyTitlePid+testing100RandPid+testing25RandPid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leftOversForTelescoping=leftOverPids-set(AllTesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fileObj = open('leftOversForTelescoping.pkl', 'w')\n",
    "pickle.dump(leftOversForTelescoping, fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "import pickle\n",
    "fileObj = open('AlltestingPids.pkl', 'w')\n",
    "pickle.dump(AllTesting, fileObj)\n",
    "fileObj.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3042, 52287, 80474, 87071, 87993)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telescoping100CandidatePid=[]\n",
    "telescoping100RandCandidatePid=[]\n",
    "telescoping25CandidatePid=[]\n",
    "telescoping25RandCandidatePid=[]\n",
    "telescoping10CandidatePid=[]\n",
    "telescoping5CandidatePid=[]\n",
    "telescoping1CandidatePid=[]\n",
    "for k, v in trainingCandidateMeta.items():\n",
    "    if k in leftOversForTelescoping:\n",
    "        if v[-1]==1.0:\n",
    "            if v[0]>100:\n",
    "                telescoping100CandidatePid.append(k)\n",
    "            if v[0]>25:\n",
    "                telescoping25CandidatePid.append(k)\n",
    "            if v[0]>10:\n",
    "                telescoping10CandidatePid.append(k)\n",
    "            if v[0]>5:\n",
    "                telescoping5CandidatePid.append(k)\n",
    "            telescoping1CandidatePid.append(k)\n",
    "\n",
    "        if v[0]>100 and v[-1]>=0.99:\n",
    "            telescoping100RandCandidatePid.append(k)\n",
    "        if v[0]>25 and v[-1]>=0.99:\n",
    "            telescoping25RandCandidatePid.append(k)\n",
    "\n",
    "len(telescoping100CandidatePid),len(telescoping25CandidatePid), len(telescoping10CandidatePid), len(telescoping5CandidatePid), len(telescoping1CandidatePid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "shuffle(telescoping100CandidatePid)\n",
    "shuffle(telescoping25CandidatePid)\n",
    "shuffle(telescoping10CandidatePid)\n",
    "shuffle(telescoping5CandidatePid)\n",
    "shuffle(telescoping1CandidatePid)\n",
    "shuffle(telescoping100RandCandidatePid)\n",
    "shuffle(telescoping25RandCandidatePid)\n",
    "telescoping100Pid=telescoping100CandidatePid[:3000]\n",
    "telescoping25Pid= list(set(telescoping25CandidatePid) - set(telescoping100Pid))[:3000]\n",
    "telescoping10Pid= list(set(telescoping10CandidatePid) - set(telescoping100Pid+telescoping25Pid))[:6000]\n",
    "telescoping5Pid= list(set(telescoping5CandidatePid) - set(telescoping100Pid+telescoping25Pid+telescoping10Pid))[:6000]\n",
    "telescoping1Pid= list(set(telescoping1CandidatePid) - set(telescoping100Pid+telescoping25Pid+telescoping10Pid+telescoping5Pid))[:3000]\n",
    "telescopingOnlyTitlePid= list(set(telescoping1CandidatePid) - set(telescoping100Pid+telescoping25Pid+telescoping10Pid+telescoping5Pid+telescoping1Pid))[:3000]\n",
    "telescoping100RandPid= list(set(telescoping100RandCandidatePid) - set(telescoping100Pid+telescoping25Pid+telescoping10Pid+telescoping5Pid+telescoping1Pid+telescopingOnlyTitlePid))[:3000]\n",
    "telescoping25RandPid= list(set(telescoping25RandCandidatePid) - set(telescoping100Pid+telescoping25Pid+telescoping10Pid+telescoping5Pid+telescoping1Pid+telescopingOnlyTitlePid+telescoping100RandPid))[:3000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 3000, 3000, 3000, 6000, 6000, 3000, 3000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(telescoping100Pid),len(telescoping100RandPid),len(telescoping25Pid),len(telescoping25RandPid),len(telescoping10Pid),len(telescoping5Pid),len(telescoping1Pid),len(telescopingOnlyTitlePid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AllTelescoping=telescoping100Pid+telescoping25Pid+telescoping10Pid+telescoping5Pid+telescoping1Pid+telescopingOnlyTitlePid+telescoping100RandPid+telescoping25RandPid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fileObj = open('telescoping25RandPid.pkl', 'w')\n",
    "pickle.dump(telescoping25RandPid, fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leftOversAfterTelescoping=leftOversForTelescoping-set(AllTelescoping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(leftOversAfterTelescoping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fileObj = open('leftOversAfterTelescoping.pkl', 'w')\n",
    "pickle.dump(leftOversAfterTelescoping, fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "import pickle\n",
    "fileObj = open('AllTelescoping.pkl', 'w')\n",
    "pickle.dump(AllTelescoping, fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
