{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "assert gensim.models.word2vec.FAST_VERSION > -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "stop='../stopwords.txt'\n",
    "emojiSynonyms='../emojiWords.txt'\n",
    "stopList=[]\n",
    "emojiMap={}\n",
    "emojis=[]\n",
    "f=codecs.open(stop,'r', encoding='utf-8')\n",
    "\n",
    "for line in f.readlines():\n",
    "    stopList.append(line.strip())\n",
    "\n",
    "f=codecs.open(emojiSynonyms,'r', encoding='utf-8')\n",
    "for line in f.readlines():\n",
    "    emoji, meaning= line.strip().split()\n",
    "    emojiMap[emoji.strip()]=' '.join(meaning.strip().split(','))\n",
    "    emojis.append(emoji.strip())\n",
    "        \n",
    "def NormalizeDates(title):    \n",
    "    fullDecades=['1930','1940','1950','1960','1970','1980','1990','2000','2010']\n",
    "    truncDecades=['30','40','50','60','70','80','90','00','10']\n",
    "    year=['2001','2002','2003','2004','2005','2006','2007','2008','2009','2011','2012','2013','2014','2015','2016','2017']\n",
    "    truncYear=['02','03','04','05','06','07','08','09','11','12','13','14','15','16','17']\n",
    "    seasons=['spring', 'summer','fall','winter','sommer', 'autumn', 'verano' ]\n",
    "    months=['january','jan','february','feb','march','april','may','june','july','august','aug','spetember','sep','october','oct','novemeber','nov','december','dec']\n",
    "    monthPairs=[('january','jan'),('february','feb'),('august','aug'),('september','sept'), ('september','sep'),('october','oct'),('november','nov'),('december','dec')]\n",
    "\n",
    "    title=title.lower().strip()\n",
    "    \n",
    "    for decade in fullDecades:\n",
    "        if decade in title:\n",
    "            newTitle=''\n",
    "            for word in title.split():\n",
    "                if decade in word:\n",
    "                    word=word.replace(decade+\"'\",decade)\n",
    "                    word=word.replace(decade+\"s\",decade)\n",
    "                    word=word.replace(decade,' '+decade+'s ')\n",
    "                newTitle=newTitle+' '+word\n",
    "            #print title+'------'+newTitle\n",
    "            title=newTitle.strip()\n",
    "\n",
    "    for truncDecade in truncDecades:\n",
    "        if truncDecade in title and ('19'+truncDecade not in title) and ('20'+truncDecade not in title):\n",
    "            newTitle=''\n",
    "            for word in title.split():\n",
    "                if truncDecade+\"'\" in word  or truncDecade+\"s\" in word or truncDecade+u\"Â´s\" in word or truncDecade+\"'s\" in word or truncDecade+\" s \" in word or truncDecade+\"ies\" in word:\n",
    "                    word=word.replace(truncDecade+\"'\",truncDecade)\n",
    "                    word=word.replace(truncDecade+\"s\",truncDecade)\n",
    "                    word=word.replace(truncDecade+\" s\",truncDecade)\n",
    "                    word=word.replace(truncDecade+u\"Â´s\",truncDecade)\n",
    "                    word=word.replace(truncDecade+\"ies\",truncDecade)\n",
    "                    if truncDecade in truncDecades[:7]:\n",
    "                        century='19'\n",
    "                    else:\n",
    "                        century='20'\n",
    "                    word=word.replace(truncDecade,' '+century+truncDecade+'s ')\n",
    "                newTitle=newTitle+' '+word\n",
    "            title=newTitle.strip()\n",
    "    if title.strip() in ['70-80','70,80,90','90/00', '70 80 90', '90 00', '80 90', '80-90','90-00', '60-70', '70 80']:\n",
    "        for truncDecade in truncDecades:\n",
    "            if truncDecade in truncDecades[:7]:\n",
    "                century='19'\n",
    "            else:\n",
    "                century='20'\n",
    "            title=title.replace(truncDecade,' '+century+truncDecade+'s ' )\n",
    "    title=title.strip()\n",
    "    for yr in year:\n",
    "        if yr in title:\n",
    "            title=title.replace(yr,' '+yr+' ')\n",
    "            \n",
    "    for yr in truncYear:\n",
    "        if yr in title and '20'+yr not in title:\n",
    "            if \"'\"+yr in title:\n",
    "                #print title\n",
    "                title=title.replace(\"'\"+yr,' 20'+yr+' ')\n",
    "                #print title\n",
    "            if yr+\"'\" in title:\n",
    "                #print title\n",
    "                title=title.replace(yr+\"'\",' 20'+yr+' ')\n",
    "                #print title\n",
    "            if '2k'+yr in title or '2K'+yr in title:\n",
    "                #print title\n",
    "                title=title.replace('2k'+yr,' 20'+yr+' ')\n",
    "                #print title\n",
    "            if '-'+yr in title :\n",
    "                #print title\n",
    "                title=title.replace('-'+yr,' 20'+yr+' ')\n",
    "                #print title\n",
    "        if yr in title and '20'+yr not in title:\n",
    "            for season in seasons:\n",
    "                if season in title:\n",
    "                    #print title\n",
    "                    title=title.replace(yr,' 20'+yr+' ')\n",
    "                    #print title\n",
    "            for month in months:\n",
    "                if month in title and '20'+yr not in title:\n",
    "                    #print title\n",
    "                    title=title.replace(yr,' 20'+yr+' ')\n",
    "                    #print '-'+title\n",
    "    for month,shortMonth in monthPairs:\n",
    "        newTitle=''\n",
    "        if shortMonth in title and month not in title:\n",
    "            #print title\n",
    "            for word in title.split():\n",
    "                if shortMonth== word:\n",
    "                    newTitle=newTitle+' '+month\n",
    "                else:\n",
    "                    newTitle=newTitle+' '+word\n",
    "            title=newTitle\n",
    "            #print '-'+title\n",
    "    title=title.strip()\n",
    "    title=' '.join(title.split())\n",
    "    return title\n",
    "\n",
    "def handleEmojis(title):\n",
    "    for emo in emojis:\n",
    "        if emo in title:\n",
    "            title=title.replace(emo,' ')\n",
    "            title=title+' '+emojiMap[emo]+' '\n",
    "            \n",
    "    title=title.replace(u'\\U0001f3fc','')\n",
    "    title=title.replace(u'\\U0001f3fd','')\n",
    "    title=title.replace(u'\\U0001f3fb','')\n",
    "    title=title.replace(u'\\U0001f3fe','')\n",
    "    title=title.replace(u'\\u200d','')\n",
    "    title=title.replace(u'\\ufe0f','')\n",
    "    title=title.replace(u'oshrug','shrug')\n",
    "    title=title.replace(u'\\ufffd','')\n",
    "    title=title.replace(u'\\U0001f37b','')\n",
    "    title=title.replace(u'\\u200d','')\n",
    "    title=title.replace(u'\\u2640','')\n",
    "    title=title.replace(u'\\u2642','')\n",
    "    title=title.replace(u'\\U0001f3b6','')\n",
    "    title=title.replace(u'\\u2728','')\n",
    "    title=title.replace(u'\\U0001f449','')\n",
    "    title=title.replace(u'\\U0001f3ff','')\n",
    "    title=title.replace(u'\\U0001f38a','')\n",
    "    title=title.replace(u'\\U0001f445','')\n",
    "    title=title.replace(u'\\U0001f608','')\n",
    "    title=title.replace(u'\\U0001f381','')\n",
    "    title=title.replace(u'\\U0001f60f','')\n",
    "    title=title.replace(u'\\U0001f4a8','')\n",
    "    title=title.replace(u'ï¿½','')\n",
    "    title=title.replace('<3',' heart love ')\n",
    "    title=title.replace(':)',' smile happy ')\n",
    "    title=title.replace(';)',' smirk happy ')\n",
    "    title=title.replace(':-)',' smile happy ')\n",
    "    title=title.replace(': )',' smile happy ')\n",
    "    title=title.replace(u'ðŸ˜‹',' smile happy ')\n",
    "    title=title.replace(u'\\u263a\\ufe0f',' smile happy ')\n",
    "    title=title.replace('r&b',' randb ')\n",
    "    title=title.replace('r & b',' randb ')\n",
    "    title=title.replace('rnb',' randb ')\n",
    "    title=title.replace(u'â€¢',' ')\n",
    "    title=title.replace(u'\\u263a\\ufe0f',' death poison ')\n",
    "    title=title.replace(u'\\u2615\\ufe0f',' coffee tea morning ')\n",
    "    title=title.replace(u'ðŸ’©',' poop ')\n",
    "    title=title.strip()\n",
    "    title=' '.join(title.split())\n",
    "    return title\n",
    "# # ' & - $ . : ! / () * ,\n",
    "import re\n",
    "def normalize_nameTitle(name):\n",
    "    name = name.lower()\n",
    "    name = NormalizeDates(name)\n",
    "    name = handleEmojis(name)\n",
    "    name = name.replace('happysmile','happy smile')\n",
    "    name = re.sub(r\"[.,\\/#\\'?\\&\\-!$%\\^\\*;:{}=\\_`~()@]\", ' ', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name\n",
    "def normalize_name(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"[.,\\/#\\'?\\&\\-!$%\\^\\*;:{}=\\_`~()@]\", ' ', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name\n",
    "\n",
    "import nltk\n",
    "def titlePlusBigrams(title):\n",
    "    bigrm = list(nltk.bigrams(title.split()))\n",
    "    bis=''\n",
    "    for x1,x2 in bigrm:\n",
    "        bis=bis+' '+x1+x2\n",
    "    return title+' '+bis.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n",
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n",
      "processing 50.....\n",
      "processing 100.....\n",
      "processing 150.....\n",
      "processing 200.....\n",
      "processing 250.....\n",
      "processing 300.....\n",
      "processing 350.....\n",
      "processing 400.....\n",
      "processing 450.....\n",
      "processing 500.....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 550.....\n",
      "processing 600.....\n",
      "processing 650.....\n",
      "processing 700.....\n",
      "processing 750.....\n",
      "processing 800.....\n",
      "processing 850.....\n",
      "processing 900.....\n",
      "processing 950.....\n",
      "processing 1000.....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor wlen in [2,5,10,20,30]:                    \\n    model = gensim.models.Word2Vec(sentences,sg=0, window=wlen, min_count=1, size=200, workers=16, iter=5)\\n    mname='./w2vModels/w2v_CBOW_w'+str(wlen)+'_200em.bin'\\n    model.save(mname)\\n    model = gensim.models.Word2Vec(sentences,sg=1, window=wlen, min_count=1, size=200, workers=16, iter=5)\\n    mname='./w2vModels/w2v_SG_w'+str(wlen)+'_200em.bin'\\n    model.save(mname)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import itertools as it\n",
    "import gensim\n",
    "import pickle\n",
    "\n",
    "path='../../data'\n",
    "backgroundFiles=pickle.load(open('./SplitsInformation/filenamesBackGroundData.pkl','rb'))\n",
    "\n",
    "class Playlists(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        count=0\n",
    "        wlen=20\n",
    "        \n",
    "        filenames = os.listdir(self.dirname)\n",
    "        for filename in sorted(filenames):\n",
    "            if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "                fullpath = os.sep.join((path, filename))\n",
    "                f = open(fullpath)\n",
    "                js = f.read()\n",
    "                f.close()\n",
    "                mpd_slice = json.loads(js)\n",
    "                for playlist in mpd_slice['playlists']:\n",
    "                    name=normalize_nameTitle(playlist['name'])\n",
    "                    name1 =titlePlusBigrams(name)\n",
    "                    trackSet=[]\n",
    "                    for track in playlist['tracks']:\n",
    "                        trackSet.append(track['track_uri'].replace('spotify:track:',''))\n",
    "                    trackSet1=trackSet[:]\n",
    "                    cnt=0\n",
    "                    l=len(trackSet)\n",
    "                    if l<wlen:\n",
    "                        trackSet.insert(l/2,name)\n",
    "                        trackSet1.insert(l/2,name1)\n",
    "                    for i in range(0,l,):\n",
    "                        trackSet.insert(i+cnt, name)\n",
    "                        trackSet1.insert(i+cnt, name1)\n",
    "                        cnt=cnt+1\n",
    "                    #for pair in list(it.combinations(trackSet, 2)):\n",
    "                    yield list(trackSet)\n",
    "                    yield list(trackSet1)\n",
    "                count += 1\n",
    "                if count%50 ==0:\n",
    "                    print \"processing \"+ str(count) +'.....'\n",
    "\n",
    "sentences = Playlists(path)\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences,sg=0, window=20, min_count=1, size=200, workers=96, iter=20)\n",
    "mname='./W2VModels/w2v_TitleAndTracks_All1MBG_CBOW_w20_200em.bin'\n",
    "model.save(mname)\n",
    "'''\n",
    "for wlen in [2,5,10,20,30]:                    \n",
    "    model = gensim.models.Word2Vec(sentences,sg=0, window=wlen, min_count=1, size=200, workers=16, iter=5)\n",
    "    mname='./w2vModels/w2v_CBOW_w'+str(wlen)+'_200em.bin'\n",
    "    model.save(mname)\n",
    "    model = gensim.models.Word2Vec(sentences,sg=1, window=wlen, min_count=1, size=200, workers=16, iter=5)\n",
    "    mname='./w2vModels/w2v_SG_w'+str(wlen)+'_200em.bin'\n",
    "    model.save(mname)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
